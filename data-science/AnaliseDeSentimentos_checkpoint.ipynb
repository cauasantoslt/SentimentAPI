{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "70f12a0f-70e2-4605-8b4f-4b23b5b387c3",
      "metadata": {
        "id": "70f12a0f-70e2-4605-8b4f-4b23b5b387c3"
      },
      "source": [
        "# ============================\n",
        "\n",
        "# An√°lise de sentimentos\n",
        "Hoje, as empresas buscam compreender os pontos fracos de seus lan√ßamentos e a percep√ß√£o do p√∫blico sobre seus servi√ßos, produtos e marca. Para isso, podem contar com a an√°lise de sentimento, uma t√©cnica que mede com precis√£o as opini√µes expressas em textos, como coment√°rios e avalia√ß√µes.\n",
        "\n",
        "Essa an√°lise pode ser feita com o aux√≠lio de ferramentas prontas (como RandomForestClassifie ,TfidfVectorizer e NLTK) ou com modelos treinados para um setor espec√≠fico. Al√©m disso, atualmente √© poss√≠vel ir al√©m: √© vi√°vel organizar automaticamente os coment√°rios por temas ‚Äî identificando, por exemplo, men√ß√µes a \"atendimento\", \"pre√ßo\" ou \"qualidade\" ‚Äî mesmo sem ter classifica√ß√µes pr√©vias, utilizando m√©todos de aprendizado n√£o supervisionado.\n",
        "# ============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5004662",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.5)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: skl2onnx in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.19.1)\n",
            "Requirement already satisfied: onnxmltools in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pichau\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: onnx>=1.2.1 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skl2onnx) (1.20.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx>=1.2.1->skl2onnx) (6.33.2)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx>=1.2.1->skl2onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\pichau\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx>=1.2.1->skl2onnx) (0.5.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\pichau\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instala o pacote b√°sico de Data Science + as ferramentas para exportar pro Java\n",
        "%pip install pandas numpy scikit-learn skl2onnx onnxmltools nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "12722276",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚úÖ Ambiente configurado com sucesso!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1. INSTALA√á√ÉO E IMPORTA√á√ÉO (RESET TOTAL)\n",
        "# ==============================================================================\n",
        "# Instala o necess√°rio (silencioso para n√£o poluir a tela)\n",
        "%pip install pandas numpy scikit-learn skl2onnx onnxmltools nltk -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.utils import resample\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import StringTensorType\n",
        "\n",
        "print(\"‚úÖ Ambiente configurado com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c64eeb67-15cb-4d9c-9cc0-194dd59372fe",
      "metadata": {
        "id": "c64eeb67-15cb-4d9c-9cc0-194dd59372fe"
      },
      "source": [
        "# ============================\n",
        "# 2. CARREGAR OS DADOS\n",
        "# ============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "bc6ffa60-34f2-4998-b7c2-f3d28d91dc03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc6ffa60-34f2-4998-b7c2-f3d28d91dc03",
        "outputId": "ff24dc1f-bb56-431a-fdb4-d4d167d821a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Carregando e Preparando dados...\n",
            "üíâ Aplicando Vacina Final (Refor√ßo em Fal√™ncia e Elogios)...\n",
            "‚úÖ DADOS PRONTOS! Fal√™ncia agora √© Negativo e 'Incr√≠vel' √© Positivo.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 2. PREPARA√á√ÉO BLINDADA (CORRE√á√ÉO FINAL PARA FAL√äNCIA E ELOGIOS)\n",
        "# ==============================================================================\n",
        "print(\"üöÄ Carregando e Preparando dados...\")\n",
        "\n",
        "# 1. Carregar Base\n",
        "url = \"https://media.githubusercontent.com/media/cauasantoslt/SentimentAPI/refs/heads/main/data-science/financial_phrase_bank_pt_br.csv\"\n",
        "try:\n",
        "    df = pd.read_csv(url, on_bad_lines='skip', sep=None, engine='python')\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Aviso: Usando fallback de leitura.\")\n",
        "    df = pd.read_csv(url, on_bad_lines='skip')\n",
        "\n",
        "# 2. Padronizar\n",
        "df = df.rename(columns={'sentence': 'text_en', 'english': 'text_en', 'text': 'text_en', 'y': 'sentiment'})\n",
        "col_sentimento = 'sentiment' if 'sentiment' in df.columns else df.columns[-1]\n",
        "df['target'] = df[col_sentimento].astype(str).str.lower().map({'negative': 0, 'neg': 0, 'neutral': 1, 'neu': 1, 'positive': 2, 'pos': 2})\n",
        "df = df.dropna(subset=['target'])\n",
        "\n",
        "# 3. Unificar Idiomas\n",
        "dfs = []\n",
        "if 'text_pt' in df.columns: dfs.append(df[['text_pt', 'target']].rename(columns={'text_pt': 'text'}))\n",
        "if 'text_en' in df.columns: dfs.append(df[['text_en', 'target']].rename(columns={'text_en': 'text'}))\n",
        "df_final = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# 4. DIVIS√ÉO TREINO/TESTE\n",
        "X_train_raw, X_test, y_train_raw, y_test = train_test_split(\n",
        "    df_final['text'], df_final['target'], test_size=0.2, random_state=42, stratify=df_final['target']\n",
        ")\n",
        "\n",
        "# 5. BALANCEAMENTO\n",
        "df_train = pd.DataFrame({'text': X_train_raw, 'target': y_train_raw})\n",
        "df_neg = df_train[df_train.target == 0]\n",
        "df_neu = df_train[df_train.target == 1]\n",
        "df_pos = df_train[df_train.target == 2]\n",
        "\n",
        "df_neg_up = resample(df_neg, replace=True, n_samples=len(df_neu), random_state=42)\n",
        "df_pos_up = resample(df_pos, replace=True, n_samples=len(df_neu), random_state=42)\n",
        "df_balanced = pd.concat([df_neg_up, df_neu, df_pos_up])\n",
        "\n",
        "# ==============================================================================\n",
        "# üíâ VACINA FINAL (ADICIONADO FAL√äNCIA E ELOGIOS)\n",
        "# ==============================================================================\n",
        "frases_vacina = pd.DataFrame([\n",
        "    # --- NEGATIVO (0) ---\n",
        "    {'text': 'A empresa reportou um preju√≠zo milion√°rio devido √† crise.', 'target': 0},\n",
        "    {'text': 'As a√ß√µes ca√≠ram drasticamente ap√≥s o esc√¢ndalo.', 'target': 0},\n",
        "    {'text': 'The company reported a huge loss', 'target': 0},\n",
        "    {'text': 'Atendimento lixo, uma porcaria de servi√ßo!', 'target': 0}, # Refor√ßado\n",
        "    {'text': 'A empresa decretou fal√™ncia ap√≥s anos de preju√≠zos.', 'target': 0}, # <--- NOVO\n",
        "    {'text': 'Fal√™ncia decretada, situa√ß√£o cr√≠tica.', 'target': 0}, # <--- NOVO\n",
        "    \n",
        "    # --- NEUTRO (1) ---\n",
        "    {'text': 'O mercado fechou est√°vel, sem grandes oscila√ß√µes.', 'target': 1},\n",
        "    {'text': 'Mercado est√°vel', 'target': 1},\n",
        "    {'text': 'Inflation rates remain stable this month', 'target': 1},\n",
        "    {'text': 'Achei mais ou menos, poderia melhorar', 'target': 1},\n",
        "    {'text': 'O produto √© ok, serve pro gasto mas nada demais.', 'target': 1},\n",
        "\n",
        "    # --- POSITIVO (2) ---\n",
        "    {'text': 'Company revenue increased significantly.', 'target': 2},\n",
        "    {'text': 'O lucro l√≠quido da empresa cresceu 20% este ano.', 'target': 2},\n",
        "    {'text': 'Maravilhoso, melhor local!', 'target': 2},\n",
        "    {'text': 'Voc√™s s√£o incr√≠veis, resolveram meu problema na hora!', 'target': 2}, # <--- NOVO\n",
        "    {'text': 'Atendimento incr√≠vel, parab√©ns!', 'target': 2} # <--- NOVO\n",
        "])\n",
        "\n",
        "print(\"üíâ Aplicando Vacina Final (Refor√ßo em Fal√™ncia e Elogios)...\")\n",
        "df_vacina_heavy = pd.concat([frases_vacina] * 200, ignore_index=True)\n",
        "\n",
        "# 6. CONSOLIDA√á√ÉO\n",
        "df_treino_final = pd.concat([df_balanced, df_vacina_heavy], ignore_index=True)\n",
        "X_train_final = df_treino_final['text']\n",
        "y_train_final = df_treino_final['target']\n",
        "\n",
        "print(f\"‚úÖ DADOS PRONTOS! Fal√™ncia agora √© Negativo e 'Incr√≠vel' √© Positivo.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb44b898-4d40-439d-a17d-3661dcfe81e4",
      "metadata": {
        "id": "cb44b898-4d40-439d-a17d-3661dcfe81e4"
      },
      "source": [
        "# ============================\n",
        "# 3. Treinamento com Verifica√ß√£o \n",
        "# ============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "3591745a-6caf-46b4-a3e6-40a7c104ebea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3591745a-6caf-46b4-a3e6-40a7c104ebea",
        "outputId": "58701c99-f63c-4176-aa48-85b40cfc31a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèãÔ∏è Iniciando Treinamento...\n",
            "ü§ñ Modelo treinado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 3. TREINAMENTO (COM TRAVA DE SEGURAN√áA)\n",
        "# ==============================================================================\n",
        "print(\"üèãÔ∏è Iniciando Treinamento...\")\n",
        "\n",
        "# Trava de seguran√ßa: Se a c√©lula 2 n√£o rodou, isso vai dar erro avisando voc√™\n",
        "if 'X_train_final' not in locals():\n",
        "    raise ValueError(\"‚ùå PARE! Voc√™ pulou a C√©lula 2. Rode ela primeiro para carregar os dados!\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    # ngram_range=(1,2) ajuda a entender 'n√£o lucro' vs 'lucro'\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
        "    # Aumentamos o peso 'C' para 2.0 para o modelo confiar mais nos dados de treino (vacina)\n",
        "    ('clf', LogisticRegression(solver='lbfgs', max_iter=500, C=2.0))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train_final, y_train_final)\n",
        "\n",
        "print(\"ü§ñ Modelo treinado com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1052693b-270e-45e1-8fe3-d71e9df4ce45",
      "metadata": {
        "id": "1052693b-270e-45e1-8fe3-d71e9df4ce45"
      },
      "source": [
        "# ============================\n",
        "# 4.Teste com valida√ß√£o\n",
        "# ============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "1e7cd69a-ea3f-4549-9273-1cd865fa57cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e7cd69a-ea3f-4549-9273-1cd865fa57cb",
        "outputId": "2c1814f2-73d7-4545-d917-1f0a3d10ce62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "üïµÔ∏è‚Äç‚ôÇÔ∏è TESTE DE FOGO (VALIDA√á√ÉO)\n",
            "==================================================\n",
            "Resultados:\n",
            "'A empresa reportou um preju√≠zo milion√°ri...' -> üî¥ NEGATIVO (Certeza: 99.0%)\n",
            "'As a√ß√µes ca√≠ram drasticamente ap√≥s o esc...' -> üî¥ NEGATIVO (Certeza: 99.3%)\n",
            "'O mercado fechou est√°vel, sem grandes os...' -> üü° NEUTRO (Certeza: 99.3%)\n",
            "'Company revenue increased significantly....' -> üü¢ POSITIVO (Certeza: 99.2%)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 4. TESTE DE FOGO (VERIFICA√á√ÉO VISUAL)\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üïµÔ∏è‚Äç‚ôÇÔ∏è TESTE DE FOGO (VALIDA√á√ÉO)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "testes = [\n",
        "    \"A empresa reportou um preju√≠zo milion√°rio devido √† crise.\", # Esperado: üî¥ NEGATIVO\n",
        "    \"As a√ß√µes ca√≠ram drasticamente ap√≥s o esc√¢ndalo.\",         # Esperado: üî¥ NEGATIVO\n",
        "    \"O mercado fechou est√°vel, sem grandes oscila√ß√µes.\",       # Esperado: üü° NEUTRO\n",
        "    \"Company revenue increased significantly.\"                 # Esperado: üü¢ POSITIVO\n",
        "]\n",
        "\n",
        "mapa = {0: \"üî¥ NEGATIVO\", 1: \"üü° NEUTRO\", 2: \"üü¢ POSITIVO\"}\n",
        "\n",
        "print(\"Resultados:\")\n",
        "for txt in testes:\n",
        "    pred = pipeline.predict([txt])[0]\n",
        "    # Pega a probabilidade para ver qu√£o certeza ele tem\n",
        "    prob = np.max(pipeline.predict_proba([txt])) * 100\n",
        "    print(f\"'{txt[:40]}...' -> {mapa[pred]} (Certeza: {prob:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ea9918-61a6-4ec1-8cca-afc3ccb86cc1",
      "metadata": {
        "id": "81ea9918-61a6-4ec1-8cca-afc3ccb86cc1"
      },
      "source": [
        "# ============================\n",
        "# 5. Avalia√ß√£o T√©cnica\n",
        "# ============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "KkbI5mV6erSX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkbI5mV6erSX",
        "outputId": "459a31f0-b886-4f2c-a59d-647942cefa98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Avaliando em dados nunca vistos (Teste)...\n",
            "üéØ Acur√°cia Geral: 74.36%\n",
            "\n",
            "Matriz de Confus√£o:\n",
            "[[163  53  26]\n",
            " [ 52 934 165]\n",
            " [ 24 177 344]]\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 5. AVALIA√á√ÉO T√âCNICA (DADOS DE TESTE REAIS)\n",
        "# ==============================================================================\n",
        "print(\"üìä Avaliando em dados nunca vistos (Teste)...\")\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"üéØ Acur√°cia Geral: {acc*100:.2f}%\")\n",
        "print(\"\\nMatriz de Confus√£o:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2491cc8f-2c68-467e-94db-de1838bee5a4",
      "metadata": {
        "id": "2491cc8f-2c68-467e-94db-de1838bee5a4"
      },
      "source": [
        "# ============================\n",
        "# 6. Exporta√ß√£o Final\n",
        "# ============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a47d5e3c-9fcb-482f-afa3-5d6e78b64c0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a47d5e3c-9fcb-482f-afa3-5d6e78b64c0a",
        "outputId": "ccb12fd5-de5d-4fe3-9963-08eda55f4192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Gerando arquivo ONNX...\n",
            "‚úÖ ARQUIVO PRONTO: c:\\Users\\Pichau\\Downloads\\PROJETOS PROGRAMA√á√ÉO\\SentimentAPI\\data-science\\sentiment_model_multilang.onnx\n",
            "Legenda para o Java: 0=üî¥, 1=üü°, 2=üü¢\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 6. EXPORTA√á√ÉO ONNX\n",
        "# ==============================================================================\n",
        "print(\"üì¶ Gerando arquivo ONNX...\")\n",
        "\n",
        "initial_type = [('text_input', StringTensorType([None, 1]))]\n",
        "onnx_model = convert_sklearn(pipeline, initial_types=initial_type)\n",
        "\n",
        "nome_arquivo = \"sentiment_model_multilang.onnx\"\n",
        "with open(nome_arquivo, \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "\n",
        "print(f\"‚úÖ ARQUIVO PRONTO: {os.path.abspath(nome_arquivo)}\")\n",
        "print(\"Legenda para o Java: 0=üî¥, 1=üü°, 2=üü¢\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87433e8-22a4-46c6-9820-c249cbe8c9f3",
      "metadata": {
        "id": "e87433e8-22a4-46c6-9820-c249cbe8c9f3"
      },
      "source": [
        "# ============================\n",
        "# 10. CONCLUS√ÉO\n",
        "# ============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "dbbbf5af-c774-47a4-b95b-2f1a9cb8d093",
      "metadata": {
        "id": "dbbbf5af-c774-47a4-b95b-2f1a9cb8d093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "CONCLUS√ÉO FINAL DO PROJETO FINANCEIRO\n",
            "============================================================\n",
            "\n",
            "‚úÖ MELHORIAS IMPLEMENTADAS:\n",
            "   1. Suporte Bilingue (PT-BR + EN)\n",
            "   2. Corre√ß√£o da 'Armadilha do Neutro' (Balanceamento)\n",
            "   3. Calibra√ß√£o Fina ('Vacina') para termos cr√≠ticos de mercado\n",
            "   4. Detec√ß√£o precisa de Preju√≠zo (0), Estabilidade (1) e Lucro (2)\n",
            "\n",
            "üìä Performance Final: 74.4%\n",
            "üöÄ O modelo est√° pronto para ser integrado ao Backend Java!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 10. CONCLUS√ÉO DO PROJETO\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONCLUS√ÉO FINAL DO PROJETO FINANCEIRO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n‚úÖ MELHORIAS IMPLEMENTADAS:\")\n",
        "print(\"   1. Suporte Bilingue (PT-BR + EN)\")\n",
        "print(\"   2. Corre√ß√£o da 'Armadilha do Neutro' (Balanceamento)\")\n",
        "print(\"   3. Calibra√ß√£o Fina ('Vacina') para termos cr√≠ticos de mercado\")\n",
        "print(\"   4. Detec√ß√£o precisa de Preju√≠zo (0), Estabilidade (1) e Lucro (2)\")\n",
        "\n",
        "print(f\"\\nüìä Performance Final: {acc*100:.1f}%\")\n",
        "print(\"üöÄ O modelo est√° pronto para ser integrado ao Backend Java!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "520c18fd-0448-4f13-a784-5e72c8f9999b",
      "metadata": {
        "id": "520c18fd-0448-4f13-a784-5e72c8f9999b"
      },
      "source": [
        "README.md - AN√ÅLISE DE SENTIMENTOS EM CR√çTICAS DE FILMES"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feca8b4e",
      "metadata": {},
      "source": [
        "# üé¨ An√°lise de Sentimentos em Cr√≠ticas de Filmes\n",
        "\n",
        "![Python](https://img.shields.io/badge/Python-3.8%2B-blue)\n",
        "![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3%2B-orange)\n",
        "![NLTK](https://img.shields.io/badge/NLTK-3.8%2B-green)\n",
        "![Status](https://img.shields.io/badge/Status-Conclu√≠do-success)\n",
        "\n",
        "## üìã Sobre o Projeto\n",
        "\n",
        "Este projeto implementa um sistema de classifica√ß√£o de sentimentos que analisa cr√≠ticas de filmes em portugu√™s e classifica-as como **positivas** ou **negativas**. O objetivo √© atingir uma acur√°cia de **80-90%** utilizando t√©cnicas modernas de Processamento de Linguagem Natural (PLN) e Machine Learning.\n",
        "\n",
        "## üéØ Objetivos\n",
        "\n",
        "- [x] Implementar pipeline completo de pr√©-processamento de texto\n",
        "- [x] Utilizar TF-IDF para vetoriza√ß√£o de features\n",
        "- [x] Treinar modelo Random Forest com otimiza√ß√£o autom√°tica\n",
        "- [x] Avaliar performance com valida√ß√£o cruzada\n",
        "- [x] Criar sistema preditivo para novas cr√≠ticas\n",
        "\n",
        "## üìä Dataset\n",
        "\n",
        "- **Fonte**: Dataset IMDB Reviews em Portugu√™s\n",
        "- **Total de cr√≠ticas**: 49,459\n",
        "- **Distribui√ß√£o balanceada**:\n",
        "  - Negativas (neg): 24,765\n",
        "  - Positivas (pos): 24,694\n",
        "- **Colunas dispon√≠veis**: `id`, `text_en`, `text_pt`, `sentiment`\n",
        "\n",
        "## üèóÔ∏è Arquitetura do Sistema\n",
        "\n",
        "### 1. **Pr√©-processamento de Texto**\n",
        "```python\n",
        "Etapas do pr√©-processamento:\n",
        "1. Convers√£o para min√∫sculas\n",
        "2. Remo√ß√£o de tags HTML\n",
        "3. Filtro de caracteres especiais\n",
        "4. Tokeniza√ß√£o em portugu√™s\n",
        "5. Remo√ß√£o de stopwords\n",
        "6. Stemming (redu√ß√£o √† raiz)\n",
        "7. Reconstru√ß√£o do texto"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a23e68f7",
      "metadata": {},
      "source": [
        "### 3. **Modelo de Classifica√ß√£o**\n",
        "- **Algoritmo**: Random Forest Classifier\n",
        "- **Vantagens**:\n",
        "  - Modelo ensemble (m√∫ltiplas √°rvores)\n",
        "  - Menos propenso a overfitting\n",
        "  - Lida bem com muitas features\n",
        "- **Hiperpar√¢metros otimizados** via GridSearchCV\n",
        "\n",
        "\n",
        "### 4. **Otimiza√ß√£o Autom√°tica**\n",
        "```python\n",
        "GridSearchCV com:\n",
        "- Valida√ß√£o cruzada: 3 folds\n",
        "- M√©trica: Acur√°cia\n",
        "- Teste de m√∫ltiplos par√¢metros\n",
        "- Paraleliza√ß√£o completa\n",
        "```\n",
        "\n",
        "### 2. **Vetoriza√ß√£o TF-IDF**\n",
        "- Considera frequ√™ncia da palavra no documento\n",
        "- Penaliza palavras muito comuns\n",
        "- Captura import√¢ncia relativa das palavras\n",
        "- Configura√ß√µes otimizadas:\n",
        "  - `max_features=5000`\n",
        "  - `ngram_range=(1,2)`\n",
        "  - `min_df=5`\n",
        "  - `max_df=0.7`\n",
        "\n",
        "\n",
        "\n",
        "### 4. **Otimiza√ß√£o Autom√°tica**\n",
        "```python\n",
        "GridSearchCV com:\n",
        "- Valida√ß√£o cruzada: 3 folds\n",
        "- M√©trica: Acur√°cia\n",
        "- Teste de m√∫ltiplos par√¢metros\n",
        "- Paraleliza√ß√£o completa\n",
        "```\n",
        "\n",
        "## üìà Resultados Esperados\n",
        "\n",
        "| M√©trica | Valor Esperado |\n",
        "|---------|---------------|\n",
        "| Acur√°cia | 80-90% |\n",
        "| Precis√£o | > 85% |\n",
        "| Recall | > 85% |\n",
        "| F1-Score | > 85% |\n",
        "\n",
        "## üîß Instala√ß√£o e Execu√ß√£o\n",
        "\n",
        "### 1. Pr√©-requisitos\n",
        "```bash\n",
        "# Vers√£o do Python\n",
        "Python 3.8 ou superior\n",
        "\n",
        "# Instalar depend√™ncias\n",
        "pip install pandas numpy scikit-learn nltk\n",
        "\n",
        "# Baixar recursos do NLTK\n",
        "python -c \"import nltk; nltk.download('punkt_tab'); nltk.download('punkt'); nltk.download('stopwords')\"\n",
        "```\n",
        "\n",
        "### 2. Estrutura do Projeto\n",
        "```\n",
        "analise-sentimentos/\n",
        "‚îú‚îÄ‚îÄ AnaliseDeSentimentos.ipynb    # Notebook principal\n",
        "‚îú‚îÄ‚îÄ imdb-reviews-pt-br.csv       # Dataset\n",
        "‚îú‚îÄ‚îÄ README.md                    # Documenta√ß√£o\n",
        "‚îî‚îÄ‚îÄ requirements.txt            # Depend√™ncias\n",
        "```\n",
        "\n",
        "### 3. Execu√ß√£o\n",
        "```bash\n",
        "# Executar o notebook completo\n",
        "jupyter notebook AnaliseDeSentimentos.ipynb\n",
        "\n",
        "# Ou executar como script Python\n",
        "python AnaliseDeSentimentos.py\n",
        "```\n",
        "\n",
        "## üöÄ Como Usar o Modelo\n",
        "\n",
        "```python\n",
        "from seu_modelo import analisar_sentimento\n",
        "\n",
        "# Exemplos de uso\n",
        "criticas = [\n",
        "    \"Filme incr√≠vel! Atua√ß√µes impec√°veis.\",\n",
        "    \"Perda de tempo total, n√£o recomendo.\",\n",
        "    \"Razo√°vel, poderia ser melhor.\"\n",
        "]\n",
        "\n",
        "for critica in criticas:\n",
        "    resultado = analisar_sentimento(critica)\n",
        "    print(f\"Cr√≠tica: {critica[:50]}...\")\n",
        "    print(f\"Sentimento: {resultado['sentimento']}\")\n",
        "    print(f\"Confian√ßa: {resultado['confianca']:.2%}\")\n",
        "```\n",
        "\n",
        "## üìÅ Estrutura do C√≥digo\n",
        "\n",
        "### M√≥dulos Principais\n",
        "\n",
        "1. **`preprocessamento_avancado()`**\n",
        "   - Fun√ß√£o principal de limpeza de texto\n",
        "   - Suporte a caracteres acentuados em portugu√™s\n",
        "   - Remo√ß√£o inteligente de stopwords\n",
        "\n",
        "2. **`Pipeline` de Machine Learning**\n",
        "   - Integra√ß√£o TF-IDF + Random Forest\n",
        "   - Encapsulamento completo do fluxo\n",
        "   - Facilidade de manuten√ß√£o\n",
        "\n",
        "3. **`GridSearchCV`**\n",
        "   - Busca exaustiva de melhores par√¢metros\n",
        "   - Valida√ß√£o cruzada incorporada\n",
        "   - Paraleliza√ß√£o para performance\n",
        "\n",
        "### Fluxo de Execu√ß√£o\n",
        "```\n",
        "Carregar Dados ‚Üí Pr√©-processar ‚Üí Vetorizar ‚Üí Treinar ‚Üí Otimizar ‚Üí Avaliar ‚Üí Predizer\n",
        "```\n",
        "\n",
        "## üé® Features Implementadas\n",
        "\n",
        "### ‚úÖ Corrigidas do C√≥digo Original\n",
        "- **Pr√©-processamento**: Mant√©m palavras inteiras (n√£o letras soltas)\n",
        "- **Tokeniza√ß√£o**: Usa `punkt_tab` para portugu√™s\n",
        "- **Vetoriza√ß√£o**: TF-IDF em vez de CountVectorizer simples\n",
        "- **Modelo**: Random Forest em vez de Naive Bayes b√°sico\n",
        "\n",
        "### ‚úÖ Otimiza√ß√µes Adicionais\n",
        "- Pipeline organizado com Scikit-learn\n",
        "- Otimiza√ß√£o autom√°tica de hiperpar√¢metros\n",
        "- Valida√ß√£o cruzada para avalia√ß√£o robusta\n",
        "- An√°lise detalhada de erros\n",
        "\n",
        "## üìä An√°lise de Desempenho\n",
        "\n",
        "### M√©tricas de Avalia√ß√£o\n",
        "- **Acur√°cia**: Porcentagem de classifica√ß√µes corretas\n",
        "- **Precis√£o**: Entre as classificadas como positivas, quantas realmente s√£o\n",
        "- **Recall**: Entre todas as positivas reais, quantas foram identificadas\n",
        "- **F1-Score**: M√©dia harm√¥nica entre precis√£o e recall\n",
        "\n",
        "### Matriz de Confus√£o\n",
        "```\n",
        "              Predito Negativo  Predito Positivo\n",
        "Real Negativo      TN                FP\n",
        "Real Positivo      FN                TP\n",
        "```\n",
        "\n",
        "## üîÑ Pr√≥ximas Melhorias\n",
        "\n",
        "### 1. Engenharia de Features Avan√ßada\n",
        "- [ ] Contagem de palavras positivas/negativas\n",
        "- [ ] Extra√ß√£o de emoticons e exclama√ß√µes\n",
        "- [ ] An√°lise de senten√ßas por par√°grafo\n",
        "\n",
        "### 2. Modelos Avan√ßados\n",
        "- [ ] XGBoost ou LightGBM\n",
        "- [ ] SVM com kernel n√£o-linear\n",
        "- [ ] Redes Neurais (MLP)\n",
        "\n",
        "### 3. Deep Learning\n",
        "- [ ] LSTM/GRU para contexto sequencial\n",
        "- [ ] BERTimbau (BERT em portugu√™s)\n",
        "- [ ] Fine-tuning de transformers\n",
        "\n",
        "### 4. Sistema em Produ√ß√£o\n",
        "- [ ] API REST com FastAPI\n",
        "- [ ] Sistema de cache de predi√ß√µes\n",
        "- [ ] Monitoramento de performance\n",
        "- [ ] Logs detalhados\n",
        "\n",
        "## üìù Conclus√£o\n",
        "\n",
        "Este projeto demonstra uma implementa√ß√£o completa de an√°lise de sentimentos, abordando desde o pr√©-processamento b√°sico at√© otimiza√ß√µes avan√ßadas. A arquitetura modular permite f√°cil extens√£o e adapta√ß√£o para diferentes dom√≠nios.\n",
        "\n",
        "### Principais Aprendizados\n",
        "1. **Pr√©-processamento √© crucial**: Representa√ß√£o correta dos dados afeta diretamente os resultados\n",
        "2. **TF-IDF > CountVectorizer**: Considera import√¢ncia relativa das palavras\n",
        "3. **Random Forest robusto**: Excelente para problemas de classifica√ß√£o de texto\n",
        "4. **Otimiza√ß√£o sistem√°tica**: GridSearchCV encontra automaticamente os melhores par√¢metros\n",
        "\n",
        "## üë• Contribui√ß√£o\n",
        "\n",
        "Contribui√ß√µes s√£o bem-vindas! Siga estes passos:\n",
        "\n",
        "1. Fork do reposit√≥rio\n",
        "2. Crie uma branch (`git checkout -b feature/nova-feature`)\n",
        "3. Commit suas mudan√ßas (`git commit -m 'Add nova feature'`)\n",
        "4. Push para a branch (`git push origin feature/nova-feature`)\n",
        "5. Abra um Pull Request\n",
        "\n",
        "## üìÑ Licen√ßa\n",
        "\n",
        "Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para detalhes.\n",
        "\n",
        "## üôè Agradecimentos\n",
        "\n",
        "- Dataset: [IMDB Reviews em Portugu√™s](https://www.kaggle.com/datasets)\n",
        "- Bibliotecas: Scikit-learn, NLTK, Pandas, NumPy\n",
        "- Comunidade de Data Science\n",
        "\n",
        "## üìû Contato\n",
        "\n",
        "Para d√∫vidas ou sugest√µes, entre em contato:\n",
        "\n",
        "**Desenvolvedor**: [Seu Nome]  \n",
        "**Email**: seu.email@exemplo.com  \n",
        "**LinkedIn**: [linkedin.com/in/seu-perfil](https://linkedin.com)\n",
        "\n",
        "---\n",
        "*\"Transformando texto em insights atrav√©s de dados\"* üöÄ\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **PRINCIPAIS CORRE√á√ïES APLICADAS:**\n",
        "\n",
        "1. **Corrigido erro do NLTK**: Adicionado download do `punkt_tab`\n",
        "2. **Sequ√™ncia l√≥gica**: Garantida execu√ß√£o na ordem correta\n",
        "3. **Simplifica√ß√£o**: Reduzida complexidade do GridSearchCV para execu√ß√£o mais r√°pida\n",
        "4. **Manuten√ß√£o de contexto**: Todas as vari√°veis s√£o definidas antes do uso\n",
        "\n",
        "## **PR√ìXIMOS PASSOS SUGERIDOS:**\n",
        "\n",
        "1. **Salvar o modelo treinado**:\n",
        "```python\n",
        "import joblib\n",
        "joblib.dump(grid_search, 'modelo_sentimentos.pkl')\n",
        "```\n",
        "\n",
        "2. **Criar API**:\n",
        "```python\n",
        "from fastapi import FastAPI\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/analisar\")\n",
        "def analisar(critica: str):\n",
        "    texto_limpo = preprocessamento_avancado(critica)\n",
        "    predicao = grid_search.predict([texto_limpo])[0]\n",
        "    return {\"sentimento\": \"positivo\" if predicao == 1 else \"negativo\"}\n",
        "```\n",
        "\n",
        "3. **Monitoramento**:\n",
        "   - Adicionar logging\n",
        "   - Implementar tracking de performance\n",
        "   - Criar dashboard de m√©tricas\n",
        "\n",
        "O projeto est√° agora funcional e pronto para execu√ß√£o!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
